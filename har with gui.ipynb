{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOxxNYYUFQjA0ULzdk7SiPo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/likhith-t-25/human-activity-recognition/blob/main/har%20with%20gui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio seaborn\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "def classify_sensor_data(file):\n",
        "    try:\n",
        "        df = pd.read_csv(file.name)\n",
        "    except Exception as e:\n",
        "        return f\"‚ùå Error reading file: {e}\", None, None\n",
        "\n",
        "    # Detect activity column\n",
        "    activity_column = None\n",
        "    for col in df.columns:\n",
        "        if 'activity' in col.lower() or 'label' in col.lower():\n",
        "            activity_column = col\n",
        "            break\n",
        "    if activity_column is None:\n",
        "        return \"‚ùå No 'activity' or 'label' column found in CSV.\", None, None\n",
        "\n",
        "    # Fill missing values\n",
        "    for col in df.columns:\n",
        "        if pd.api.types.is_numeric_dtype(df[col]):\n",
        "            df[col].fillna(df[col].median(), inplace=True)\n",
        "        else:\n",
        "            df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "    X = df.drop(activity_column, axis=1)\n",
        "    y = df[activity_column]\n",
        "\n",
        "    # Encode and scale\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y)\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Dynamic test size handling\n",
        "    num_classes = len(np.unique(y_encoded))\n",
        "    min_test_size = num_classes / len(df)\n",
        "    test_size = max(0.2, min_test_size)\n",
        "\n",
        "    try:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_scaled, y_encoded, test_size=test_size, random_state=42, stratify=y_encoded\n",
        "        )\n",
        "    except ValueError as e:\n",
        "        return f\"‚ùå Error splitting data: {e}\", None, None\n",
        "\n",
        "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_)\n",
        "    summary = f\"‚úÖ Accuracy: {acc * 100:.2f}%\\n\\n{report}\"\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    cm_buf = io.BytesIO()\n",
        "    plt.figure(figsize=(6, 5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(cm_buf, format='png')\n",
        "    plt.close()\n",
        "    cm_buf.seek(0)\n",
        "    cm_img = Image.open(cm_buf)\n",
        "\n",
        "    # Feature Importance\n",
        "    feat_buf = io.BytesIO()\n",
        "    feat_df = pd.DataFrame({'Feature': X.columns, 'Importance': model.feature_importances_})\n",
        "    feat_df = feat_df.sort_values(by='Importance', ascending=False)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.barplot(x='Importance', y='Feature', data=feat_df)\n",
        "    plt.title(\"Feature Importance\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(feat_buf, format='png')\n",
        "    plt.close()\n",
        "    feat_buf.seek(0)\n",
        "    feat_img = Image.open(feat_buf)\n",
        "\n",
        "    return summary, cm_img, feat_img\n",
        "\n",
        "# Launch Gradio GUI\n",
        "gr.Interface(\n",
        "    fn=classify_sensor_data,\n",
        "    inputs=gr.File(label=\"üìÅ Upload Sensor CSV\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"üìã Classification Report\"),\n",
        "        gr.Image(label=\"üìä Confusion Matrix\", type=\"pil\"),\n",
        "        gr.Image(label=\"üîç Feature Importance\", type=\"pil\")\n",
        "    ],\n",
        "    title=\"Sensor-Based Human Activity Recognition (HAR)\",\n",
        "    description=\"Upload a CSV file containing gyroscope + accelerometer data to classify human activities using Random Forest.\"\n",
        ").launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "664K5_sNSJFq",
        "outputId": "9ba8c66a-583f-48ad-c408-f579f7cc9990"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://32413bdb5a7e11cecb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://32413bdb5a7e11cecb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}